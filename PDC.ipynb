{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7cce5d5",
   "metadata": {},
   "source": [
    "# Курсовая работа по дисциплине ПГПиПОД"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f9a99a",
   "metadata": {},
   "source": [
    "Выполнил: студент группы М8О-114М-22 Дмитроченко Б.А."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b39bfe",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e7870",
   "metadata": {},
   "source": [
    "С помощью MPI отправить на разные ядра части датасета, обучить его на каждом ядре, а затем собрать результаты предиктов на ядре 0 и провести ансамблевое голосование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604eb88",
   "metadata": {},
   "source": [
    "### Используемый датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f349d60",
   "metadata": {},
   "source": [
    "Для работы использовался датасет MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26da3d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpi4py in c:\\users\\bonjo\\miniconda3\\lib\\site-packages (3.1.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install mpi4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aef07da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing MNISTSet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MNISTSet.py\n",
    "import torch, torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "\n",
    "T = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "\n",
    "train_data = torchvision.datasets.MNIST('mnist_data', train=True, download=True, transform=T)\n",
    "\n",
    "test_data = torchvision.datasets.MNIST('mnist_data', train=False, download=True, transform=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3a68cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing DataLoader.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile DataLoader.py\n",
    "from torch.utils.data import DataLoader\n",
    "import torch, torchvision\n",
    "from MNISTSet import train_data,test_data\n",
    "def DataLoader(batchSize, numWorkers,shuffle = False,):\n",
    "  loaders = {\n",
    "  'train_dl' : torch.utils.data.DataLoader(train_data, batch_size=batchSize, shuffle=shuffle, num_workers=numWorkers),\n",
    "  \n",
    "  'test_dl'  : torch.utils.data.DataLoader(test_data, batch_size=batchSize, shuffle=True, num_workers=numWorkers),\n",
    "  }\n",
    "  return loaders    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85a39a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Model.py\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(1, 6, 5, padding=2),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(2, stride=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(6, 16, 5, padding=0),    \n",
    "            nn.ReLU(),                      \n",
    "            nn.AvgPool2d(2, stride=2),                \n",
    "        )\n",
    "        self.out = nn.Linear(400, 120, 84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0065667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Main.py\n",
    "from mpi4py import MPI\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from DataLoader import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from Model import CNN\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "def train_model(num_epochs, criterion, test_dataloader, rank, batch_size, optimizer, model, train_dataloader, val_dataloader):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model_best = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        accuracy = 0\n",
    "        dataset_sizes_train = len(train_dataloader)\n",
    "        model.train()\n",
    "        if rank == 0:\n",
    "            i = 0\n",
    "            for images, labels in tqdm(train_dataloader):\n",
    "                comm.send((images, labels),dest = i%(p-1)+1)\n",
    "                i+=1\n",
    "                if rank != 0:\n",
    "                    for i in range(len(train_dataloader)):\n",
    "                        if i % (p - 1) + 1 == rank:\n",
    "                            (images,lables) = comm.recv(source=0)\n",
    "                            images = images.to(device)\n",
    "                            lables = lables.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output,lables)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        running_loss = running_loss / dataset_sizes_train\n",
    "        print(\"Epoch of train:\", epoch + 1,\"Loss: [\", running_loss, \"]\", \"rank: \", rank)\n",
    "            \n",
    "    MPI.Comm.Barrier(MPI.COMM_WORLD)\n",
    "      \n",
    "    accuracy = 0\n",
    "    validate_loss = 0.0\n",
    "    dataset_sizes_val = len(val_dataloader)\n",
    "    if rank != 0:\n",
    "        model.eval()\n",
    "    if rank == 0:\n",
    "        i = 0\n",
    "        for images, labels in tqdm(val_dataloader):\n",
    "            comm.send((images,labels), dest=i % (p - 1) + 1)\n",
    "            i+=1\n",
    "    if rank != 0:\n",
    "        for i in range(len(val_dataloader)):\n",
    "            if i % (p - 1) + 1 == rank:\n",
    "                (images,lables) = comm.recv(source=0)\n",
    "                images = images.to(device)\n",
    "                lables = lables.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(images)\n",
    "                loss = criterion(output,lables)\n",
    "                validate_loss += loss.item() * images.size(0)\n",
    "                pred_y = torch.max(output, 1)[1].data.squeeze()\n",
    "        validate_loss = validate_loss / dataset_sizes_val\n",
    "        print(\"Epoch of validation:\", epoch + 1,\"Loss: \",validate_loss, rank)\n",
    "        MPI.Comm.Barrier(MPI.COMM_WORLD) \n",
    "        if rank != 0:\n",
    "            if epoch == 0:\n",
    "                model_best = validate_loss\n",
    "            if validate_loss <= model_best:\n",
    "                model_best = validate_loss\n",
    "                torch.save(model.state_dict(), f\"./weights/model_{rank}.pth\")\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    comm = MPI.COMM_WORLD\n",
    "    my_rank = comm.Get_rank()\n",
    "    p = comm.Get_size()\n",
    "    num_epochs = 3\n",
    "    batch_size = 30\n",
    "    num_workers = 4\n",
    "    train_dataloader = DataLoader(batch_size,num_workers)['train_dl']\n",
    "    validate_dataloader = DataLoader(batch_size,num_workers)['test_dl']\n",
    "    model = CNN()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = train_model(num_epochs,criterion,validate_dataloader,my_rank,\n",
    "                           batch_size,optimizer,model,train_dataloader,validate_dataloader)\n",
    "    MPI.Finalize   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d95b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mpiexec -np 6 python Main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffecc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Test.py\n",
    "from mpi4py import MPI\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from DataLoader import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from Model import CNN\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "def test(model, criterion, dataloader_test, dataset_sizes_test):\n",
    "    score = 0\n",
    "    runing_loss = 0.0\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        if rank != 0:\n",
    "            print(\"Start proccess number \",rank)\n",
    "            for image, label in tqdm(dataloader_test): \n",
    "                output = model(image)\n",
    "                comm.send(output, dest=0, tag=0) \n",
    "                if rank == 1:\n",
    "                    comm.send(label, dest=0, tag=1)\n",
    "                _, preds = torch.max(output, 1)\n",
    "                loss = criterion(output, label)\n",
    "                runing_loss += loss.item() * image.size(0)\n",
    "                score += torch.sum(preds == label.data)\n",
    "            epoch_acc = score.double() / dataset_sizes_test\n",
    "            runing_loss = runing_loss / dataset_sizes_test\n",
    "            print(\"Test process \", rank, \": score: [\", epoch_acc.item(), \"], loss: [\", runing_loss, \"]\")\n",
    "        \n",
    "        MPI.Comm.Barrier(MPI.COMM_WORLD)\n",
    "        result = 0\n",
    "        if rank == 0:\n",
    "            print(\"Start proccess number \",rank)\n",
    "            for i in tqdm(range(len(dataloader_test))):\n",
    "                label = comm.recv(source=1, tag=1) \n",
    "                for procid in range(1, p):\n",
    "                    output = comm.recv(source=procid, tag=0)\n",
    "                    if procid == 1:\n",
    "                        result_all_models = output\n",
    "                    else:\n",
    "                        result_all_models += output\n",
    "                _, preds = torch.max(result_all_models, 1)\n",
    "                result += torch.sum(preds == label.data)\n",
    "            result = result.double() / dataset_sizes_test\n",
    "            print(\"Test process result\", rank, result.item())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    p = comm.Get_size()\n",
    "    num_epochs = 3\n",
    "    batch_size = 30\n",
    "    num_workers = 4\n",
    "    train_dataloader = DataLoader(batch_size,num_workers)['train_dl']\n",
    "    validate_dataloader = DataLoader(batch_size,num_workers)['test_dl']\n",
    "    model = CNN()\n",
    "    if(rank != 0):\n",
    "        model.load_state_dict(torch.load(f'/content/weights/model_{rank}.pth'))\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        model = test(model,criterion,validate_dataloader,len(validate_dataloader) * batch_size)\n",
    "    MPI.Finalize    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21096cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mpirun -np 6 python Test.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
